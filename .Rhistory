family = poisson(link = "log"))
summary(bikes_poisson)
#Temperature
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = temp)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
#Humidity
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = hum)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
#Windspeed
ggplot(data = bikes, mapping = aes(y = log(cnt + 1), x = windspeed)) +
geom_point() +
theme_bw() +
theme(aspect.ratio = 1)
# Use added variable plots for any continuous predictors you included in the
# model
avPlots(bikes_poisson, terms = ~ temp + hum + windspeed)
bikes.cooks <- data.frame("cooks.distance" = cooks.distance(bikes_poisson))
bikes.cooks$obs <- 1:nrow(bikes)
ggplot(data = bikes.cooks) +
geom_point(mapping = aes(x = obs, y = abs(cooks.distance))) +
geom_hline(mapping = aes(yintercept = 4/ length(obs)),
color = "red", linetype = "dashed") +  # for n > 30
geom_hline(mapping = aes(yintercept = 1),
color = "red", linetype = "dashed") +  # for n > 30
theme_bw() +
theme(aspect.ratio = 1)
bikes$cooksd <- cooks.distance(bikes_poisson)
bikes %>%
mutate(rowNum = row.names(bikes)) %>%  # save original row numbers
filter(cooksd > 4 / length(cooksd)) %>%  # select potential outliers
arrange(desc(cooksd))
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
library(car)  # needed for added-variable plots and dfbetas
library(corrplot)  # colored correlation matrix
# install.packages("devtools")
# devtools::install_github("thomasp85/patchwork")
library(patchwork)
FatComplete <- read_table("BodyFat.txt")
bodyfat<- FatComplete %>%
select(-row)
summary(bodyfat)
pairs(bodyfat, pch = 19)
round(cor(bodyfat), 2)
corrplot(cor(bodyfat), type = "upper")
bodyfat_lm <- lm(brozek ~ ., data = bodyfat)
summary(bodyfat_lm)
bodyfat$residuals <- bodyfat_lm$residuals
bodyfat_resid_vs_fit <- autoplot(bodyfat_lm, which = 1, ncol = 1, nrow = 1) +
theme(aspect.ratio = 1)
bodyfat_resid_vs_fit
plot4
## Loading Libraries
library(tidyverse)
library(vroom)
library(DataExplorer)
library(patchwork)
# Load data
bike <- vroom('./train.csv')
library(tidyverse) # Data Wrangling
library(DataExplorer) # Data visualization
library(vroom) # Import data
library(tidymodels) # Modeling
library(rpart) # For random forest
library(reshape2) # To be able to melt my table
library(skimr) # for skim function
setwd('~/College/Stat348/ForestCoverType')
trainSet <- vroom('./train.csv')
testSet <- vroom('./test3.csv')
trainSet$Cover_Type <- as.factor(trainSet$Cover_Type)
# Model
rf_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=50) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("classification")
smaller <- head(trainSet, 100)
## Recipe
my_recipe <- recipe(Cover_Type~., data=smaller) %>%
step_rm('Id') %>%
step_zv(all_predictors()) %>%# remove all zero variance predictors
step_normalize(all_numeric_predictors())  # normalized all numeric predictors
## Workflow
rf_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rf_mod)
## Set up grid of tuning values
tuning_grid <- grid_regular(mtry(range = c(1,52)),
levels = 5,
min_n()) # Maybe don't use levels
## Set up K-fold CV (This usually takes sometime)
folds <- vfold_cv(trainSet, v = 5, repeats=1)
CV_results <- rf_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy))
## Find best tuning parameters
bestTune <- CV_results %>%
select_best("accuracy")
final_wf <- rf_wf %>%
finalize_workflow(bestTune) %>%
fit(data=trainSet)
preds <- final_wf %>%
predict(new_data = testSet, type = 'class')
head(smaller)
head(testSet)
testSet <- vroom('./test.csv')
preds <- final_wf %>%
predict(new_data = testSet, type = 'class')
preds
?fit_members()
library(tidyverse) # Data Wrangling
library(DataExplorer) # Data visualization
library(vroom) # Import data
library(tidymodels) # Modeling
library(rpart) # For random forest
library(reshape2) # To be able to melt my table
library(skimr) # for skim function
library(stacks) # For stack model
library(lightgbm) # For xgboost model
library(bonsai)
trainSet <- vroom('./train.csv')
testSet <- vroom('./test.csv')
trainSet$Cover_Type <- as.factor(trainSet$Cover_Type)
# Recipe
my_recipe <- recipe(Cover_Type~., data=trainSet) %>%
step_rm('Id') %>%
step_zv(all_predictors()) %>%# remove all zero variance predictors
step_normalize(all_numeric_predictors())  # normalized all numeric predictors
## Split data for CV
folds <- vfold_cv(trainSet, v = 5, repeats=1)
plg_mod <- logistic_reg(mixture=tune(), penalty=tune()) %>%
set_engine("glmnet")
# Workflow
plg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(plg_mod)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Run the CV
plg_models <- amazon_workflow %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy),
control = untunedModel)
## Run the CV
plg_models <- plg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy),
control = untunedModel)
## Run the CV
plg_models <- plg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy))
show_notes(.Last.tune.result)
plg_mod <- logistic_reg(mixture=tune(), penalty=tune(), family = "multinomial") %>%
set_engine("glmnet")
plg_mod <- logistic_reg(mixture=tune(), penalty=tune()) %>%
set_engine("glmnet", family = "multinomial")
# Workflow
plg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(plg_mod)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Run the CV
plg_models <- plg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy))
plg_mod <- multinom_reg(mixture=tune(), penalty=tune()) %>%
set_engine("glmnet", family = "multinomial")
# Workflow
plg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(plg_mod)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) ## L^2 total tuning possibilities
## Run the CV
plg_models <- plg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy))
# load("FCTplg.Rdata")
save(plg_models, file = "FCTplg.Rdata")
plg_models  %>%
select_best("accuracy")
library(doParallel)
num_cores <- parallel::detectCores() #How many cores do I have?
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
# LOAD PACKAGES -----------------------------------------------------------
library(tidyverse) # Data Wrangling
library(DataExplorer) # Data visualization
library(vroom) # Import data
library(tidymodels) # Modeling
library(rpart) # For random forest
library(reshape2) # To be able to melt my table
library(skimr) # for skim function
library(stacks) # For stack model
library(lightgbm) # For xgboost model
library(bonsai) # For xgboost model
### MULTIVARIABLE PROBLEM ###
library(doParallel)
num_cores <- parallel::detectCores() #How many cores do I have?
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
# LOAD PACKAGES -----------------------------------------------------------
library(tidyverse) # Data Wrangling
library(DataExplorer) # Data visualization
library(vroom) # Import data
library(tidymodels) # Modeling
library(rpart) # For random forest
library(reshape2) # To be able to melt my table
library(skimr) # for skim function
library(stacks) # For stack model
library(lightgbm) # For xgboost model
library(bonsai) # For xgboost model
setwd('~/College/Stat348/ForestCoverType')
trainSet <- vroom('./train.csv')
testSet <- vroom('./test.csv')
trainSet$Cover_Type <- as.factor(trainSet$Cover_Type)
my_recipe <- recipe(Cover_Type~., data=trainSet) %>%
step_rm('Id') %>%
step_zv(all_predictors()) %>%# remove all zero variance predictors
step_normalize(all_numeric_predictors())
## Split data for CV
folds <- vfold_cv(trainSet, v = 5, repeats=1)
## Control Settings for Stacking models
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
load("FCT.Rdata")
View(CV_results)
trainSet <- vroom('./train.csv')
testSet <- vroom('./test.csv')
trainSet$Cover_Type <- as.factor(trainSet$Cover_Type)
my_recipe <- recipe(Cover_Type~., data=trainSet) %>%
step_rm('Id') %>%
step_zv(all_predictors()) %>%# remove all zero variance predictors
step_normalize(all_numeric_predictors())  # normalized all numeric predictors
# glm target encoding encoding precitors
## Split data for CV
folds <- vfold_cv(trainSet, v = 5, repeats=1)
## Control Settings for Stacking models
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
load("FCT.Rdata")
load("FCTplg.Rdata")
## Specify which models to include
forest_stack <- stacks() %>%
add_candidates(CV_results) %>%
# add_candidates(bst_models) %>%
add_candidates(plg_models)
## Find best tuning parameters
bestTune <- plg_models  %>%
select_best("accuracy")
final_wf <- plg_models %>%
finalize_workflow(bestTune) %>%
fit(data=trainSet)
## Run the CV
plg_models <- plg_wf %>%
tune_grid(resamples=folds,
grid=tuning_grid,
metrics=metric_set(accuracy))
## Find best tuning parameters
bestTune <- plg_models  %>%
select_best("accuracy")
# Finalize Workflow
final_wf <- plg_models %>%
finalize_workflow(bestTune) %>%
fit(data=trainSet)
plg_mod <- multinom_reg(mixture=tune(), penalty=tune()) %>%
set_engine("glmnet", family = "multinomial")
# Workflow
plg_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(plg_mod)
## Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5)
## Find best tuning parameters
bestTune <- plg_models  %>%
select_best("accuracy")
# Finalize Workflow
final_wf <- plg_models %>%
finalize_workflow(bestTune) %>%
fit(data=trainSet)
View(plg_models)
bestTune
# Finalize Workflow
final_wf <- plg_wf %>%
finalize_workflow(bestTune) %>%
fit(data=trainSet)
# Predict
preds <- final_wf %>%
predict(new_data = testSet)
# Format table
testSet$Cover_Type <- preds$.pred_class
results <- testSet %>%
select(Id, Cover_Type)
# get csv file
vroom_write(results, 'submissions.csv', delim = ",")
# Model
rf_mod <- rand_forest(mtry = tune(),
min_n=tune(),
trees=300) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("classification")
## Workflow
rf_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rf_mod)
## Set up grid of tuning values
tuning_grid <- grid_regular(mtry(range = c(1,52)),
levels = 5,
min_n()) # Maybe don't use levels
## Find best tuning parameters
bestTune <- CV_results  %>%
select_best("accuracy")
bestTune
# Finalize Workflow
final_wf <- rf_wf %>%
finalize_workflow(bestTune) %>%
fit(data=trainSet)
# Predict
preds <- final_wf %>%
predict(new_data = testSet)
# Format table
testSet$Cover_Type <- preds$.pred_class
results <- testSet %>%
select(Id, Cover_Type)
# get csv file
vroom_write(results, 'submissions.csv', delim = ",")
boost_model <- boost_tree(tree_depth=6,
trees=30,
learn_rate=0.1) %>%
set_engine("lightgbm") %>%
set_mode("classification")
# Workflow
bt_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(boost_model)
# Tune
tuneGrid <- grid_regular(learn_rate(),
levels = 3)
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
stopCluster(cl)
library(doParallel)
num_cores <- parallel::detectCores() #How many cores do I have?
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
# Cross Validation
bst_models <- bt_wf %>%
tune_grid(resamples=folds,
grid=tuneGrid,
metrics=metric_set(accuracy),
control = tunedModel)
# load("FCTbst.Rdata")
save(bst_models, file = "FCTbst.Rdata")
load("FCTrf.Rdata")
## Specify which models to include
forest_stack <- stacks() %>%
add_candidates(rf_models) %>%
# add_candidates(bst_models) %>%
add_candidates(plg_models)
collect_notes()
collect_notes(rf_models)
library(tidyverse) # Data Wrangling
library(DataExplorer) # Data visualization
library(vroom) # Import data
library(tidymodels) # Modeling
library(rpart) # For random forest
library(reshape2) # To be able to melt my table
library(skimr) # for skim function
library(stacks) # For stack model
library(lightgbm) # For xgboost model
library(bonsai) # For xgboost model
trainSet <- vroom('./train.csv')
testSet <- vroom('./test.csv')
trainSet$Cover_Type <- as.factor(trainSet$Cover_Type)
my_recipe <- recipe(Cover_Type~., data=trainSet) %>%
step_rm('Id') %>%
step_zv(all_predictors()) %>%# remove all zero variance predictors
step_normalize(all_numeric_predictors())  # normalized all numeric predictors
# glm target encoding encoding precitors
## Split data for CV
folds <- vfold_cv(trainSet, v = 5, repeats=1)
## Control Settings for Stacking models
untunedModel <- control_stack_grid()
tunedModel <- control_stack_resamples()
# Cross Validation
rf_models <- rf_wf %>%
tune_grid(resamples=folds,
#grid=tuning_grid,
metrics=metric_set(accuracy),
control=untunedModel)
# Model
rf_mod <- rand_forest(mtry = 26,
min_n=2,
trees=300) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("classification")
# Model
rf_mod <- rand_forest(mtry = 26,
min_n=2,
trees=300) %>% #Type of model
set_engine("ranger") %>% # What R function to use
set_mode("classification")
preds <- rf_mod %>%
fit(data=trainSet)
# Worflow
rf_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(rf_mod)
# Predict
preds <- rf_wf %>%
fit(data=trainSet)
preds <- preds %>%
predict(new_data = testSet)
preds
unique(preds$.pred_class)
load("FCTplg.Rdata")
plg_models  %>%
select_best("accuracy")
boost_model <- boost_tree(tree_depth=6,
trees=30,
learn_rate=0.1) %>%
set_engine("lightgbm") %>%
set_mode("classification")
### MULTIVARIABLE PROBLEM ###
library(doParallel)
num_cores <- parallel::detectCores() #How many cores do I have?
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
# Workflow
bt_wf <- workflow() %>%
add_recipe(my_recipe) %>%
add_model(boost_model)
# Predict
preds <- rf_wf %>%
fit(data=trainSet) %>%
predict(new_data = testSet)
preds
# Format table
testSet$Cover_Type <- forest_pred_stack$.pred_class
# Format table
testSet$Cover_Type <- preds$.pred_class
results <- testSet %>%
select(Id, Cover_Type)
# get csv file
vroom_write(results, 'submissions.csv', delim = ",")
## Specify which models to include
forest_stack <- stacks() %>%
add_candidates(rf_wf) %>%
add_candidates(bt_wf)
# Cross-validation for rf_wf
rf_results <- rf_wf %>%
fit_resamples(resamples = folds,
metrics = metric_set(accuracy))
bt_results <- bt_wf %>%
fit_resamples(resamples = folds,
metrics = metric_set(accuracy))
# Cross-validation
rf_results <- rf_wf %>%
fit_resamples(resamples = folds,
metrics = metric_set(accuracy),
control=untunedModel)
bt_results <- bt_wf %>%
fit_resamples(resamples = folds,
metrics = metric_set(accuracy),
control=untunedModel)
## Specify which models to include
forest_stack <- stacks() %>%
add_candidates(rf_results) %>%
add_candidates(bt_results)
num_cores <- parallel::detectCores() #How many cores do I have?
cl <- makePSOCKcluster(num_cores)
registerDoParallel(cl)
# Cross-validation
rf_results <- rf_wf %>%
fit_resamples(resamples = folds,
metrics = metric_set(roc_auc),
control=untunedModel)
bt_results <- bt_wf %>%
fit_resamples(resamples = folds,
metrics = metric_set(roc_auc),
control=untunedModel)
## Specify which models to include
forest_stack <- stacks() %>%
add_candidates(rf_results) %>%
add_candidates(bt_results)
# Fit the stacked model
fitted_forest_stack <-  forest_stack %>%
blend_predictions() %>%
fit_members()
# Predict
forest_pred_stack <- fitted_forest_stack %>%
predict(new_data = testSet)
